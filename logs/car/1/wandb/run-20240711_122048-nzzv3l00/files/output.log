
[34m[1mLogs will be synced with wandb.
Traceback (most recent call last):
  File "train.py", line 109, in <module>
    train(parse_cfg(Path().cwd() / __CONFIG__))
  File "train.py", line 64, in train
    episode += (s, action, reward, done)
  File "/home/jeongtae/RLMPPI/src/algorithm/helper.py", line 161, in __add__
    self.add(*transition)
  File "/home/jeongtae/RLMPPI/src/algorithm/helper.py", line 166, in add
    self.action = torch.cat((self.action, torch.tensor([action], dtype=self.action.dtype, device=self.device)))
ValueError: only one element tensors can be converted to Python scalars