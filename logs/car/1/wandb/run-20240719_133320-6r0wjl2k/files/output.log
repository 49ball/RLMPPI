[34m[1mLogs will be synced with wandb.
 [34mtrain[39m   [30mE:[39m 1                [30mS:[39m 0                [30mR:[39m -5.0             [30mT:[39m 0:00:00
 [32meval[39m    [30mE:[39m 1                [30mS:[39m 0                [30mR:[39m -4.0             [30mT:[39m 0:00:00
 [34mtrain[39m   [30mE:[39m 2                [30mS:[39m 1,000            [30mR:[39m -5.0             [30mT:[39m 0:00:04
 [34mtrain[39m   [30mE:[39m 3                [30mS:[39m 2,000            [30mR:[39m -5.0             [30mT:[39m 0:00:04
 [34mtrain[39m   [30mE:[39m 4                [30mS:[39m 3,000            [30mR:[39m -5.0             [30mT:[39m 0:00:04
 [34mtrain[39m   [30mE:[39m 5                [30mS:[39m 4,000            [30mR:[39m -5.0             [30mT:[39m 0:00:04
 [34mtrain[39m   [30mE:[39m 6                [30mS:[39m 5,000            [30mR:[39m -5.0             [30mT:[39m 0:00:04
 [34mtrain[39m   [30mE:[39m 7                [30mS:[39m 6,000            [30mR:[39m -5.0             [30mT:[39m 0:00:04
 [34mtrain[39m   [30mE:[39m 8                [30mS:[39m 7,000            [30mR:[39m -5.0             [30mT:[39m 0:00:04
 [34mtrain[39m   [30mE:[39m 9                [30mS:[39m 8,000            [30mR:[39m -5.0             [30mT:[39m 0:00:04
 [34mtrain[39m   [30mE:[39m 10               [30mS:[39m 9,000            [30mR:[39m 22.5             [30mT:[39m 0:00:04
> /home/jeongtae/RLMPPI/src/algorithm/helper.py(269)sample()
-> return s, next_s, action, reward.unsqueeze(2), done.unsqueeze(2), idxs, weights
Traceback (most recent call last):
  File "train.py", line 146, in <module>
    train(parse_cfg(Path().cwd() / __CONFIG__))
  File "train.py", line 114, in train
    train_metrics.update(agent.update(buffer,step+i))
  File "/home/jeongtae/RLMPPI/src/algorithm/tdmpc.py", line 182, in update
    s, next_ses, action, reward, done, idxs, weights = replay_buffer.sample() #버퍼들중 무작위 값 불러와서 값들 초기화
  File "/home/jeongtae/RLMPPI/src/algorithm/helper.py", line 269, in sample
    return s, next_s, action, reward.unsqueeze(2), done.unsqueeze(2), idxs, weights
  File "/home/jeongtae/RLMPPI/src/algorithm/helper.py", line 269, in sample
    return s, next_s, action, reward.unsqueeze(2), done.unsqueeze(2), idxs, weights
  File "/home/jeongtae/anaconda3/envs/RLMPPI/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/home/jeongtae/anaconda3/envs/RLMPPI/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit