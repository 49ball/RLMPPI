[34m[1mLogs will be synced with wandb.
 [34mtrain[39m   [30mE:[39m 1                [30mS:[39m 0                [30mR:[39m -5.7             [30mT:[39m 0:00:00
> /home/jeongtae/RLMPPI/src/logger.py(108)record()
-> line.set_data(x,y)
-0.011361549608409405
-0.009687982499599457
0.7071441411972046
Traceback (most recent call last):
  File "train.py", line 146, in <module>
    train(parse_cfg(Path().cwd() / __CONFIG__))
  File "train.py", line 137, in train
    common_metrics['episode_reward'] = evaluate(env, agent, cfg.eval_episodes, step, env_step ,eval_numbering, cfg, L.video)
  File "train.py", line 48, in evaluate
    if video: video.record(s)
  File "/home/jeongtae/RLMPPI/src/logger.py", line 108, in record
    line.set_data(x,y)
  File "/home/jeongtae/RLMPPI/src/logger.py", line 108, in record
    line.set_data(x,y)
  File "/home/jeongtae/anaconda3/envs/RLMPPI/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/home/jeongtae/anaconda3/envs/RLMPPI/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit